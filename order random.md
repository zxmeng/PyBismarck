### dense-logit


python bismarck_front.py dense-logit-spec.py
A shuffled table __bismarck_shuffled_forest_1 is created for training
iteration 1 	loss: 347915.291249 	improvement:  None
iteration 2 	loss: 347544.660764 	improvement:  0.00106528943795
iteration 3 	loss: 347530.402728 	improvement:  4.10250467858e-05
iteration 4 	loss: 347530.004921 	improvement:  1.14466671375e-06
iteration 5 	loss: 347530.050094 	improvement:  -1.29981245877e-07
iteration 6 	loss: 347530.064637 	improvement:  -4.1847385588e-08
iteration 7 	loss: 347530.067423 	improvement:  -8.01780122964e-09
iteration 8 	loss: 347530.068096 	improvement:  -1.93439095426e-09
iteration 9 	loss: 347530.068232 	improvement:  -3.91986219947e-10
iteration 10 	loss: 347530.068259 	improvement:  -7.85227941387e-11
iteration 11 	loss: 347530.068265 	improvement:  -1.57309551824e-11
iteration 12 	loss: 347530.068266 	improvement:  -3.08465536924e-12
iteration 13 	loss: 347530.068266 	improvement:  -6.35790399174e-13
iteration 14 	loss: 347530.068266 	improvement:  -1.23774790566e-13
iteration 15 	loss: 347530.068266 	improvement:  -8.70945752292e-15
iteration 16 	loss: 347530.068266 	improvement:  -1.72514254781e-14
iteration 17 	loss: 347530.068266 	improvement:  -2.84732265172e-15
iteration 18 	loss: 347530.068266 	improvement:  0.0
iteration 19 	loss: 347530.068266 	improvement:  0.0
iteration 20 	loss: 347530.068266 	improvement:  0.0
iteration 21 	loss: 347530.068266 	improvement:  0.0
iteration 22 	loss: 347530.068266 	improvement:  0.0
iteration 23 	loss: 347530.068266 	improvement:  0.0
iteration 24 	loss: 347530.068266 	improvement:  0.0
iteration 25 	loss: 347530.068266 	improvement:  0.0
iteration 26 	loss: 347530.068266 	improvement:  0.0
iteration 27 	loss: 347530.068266 	improvement:  0.0
iteration 28 	loss: 347530.068266 	improvement:  0.0
iteration 29 	loss: 347530.068266 	improvement:  0.0
iteration 30 	loss: 347530.068266 	improvement:  0.0
iteration 31 	loss: 347530.068266 	improvement:  0.0
iteration 32 	loss: 347530.068266 	improvement:  0.0
iteration 33 	loss: 347530.068266 	improvement:  0.0
iteration 34 	loss: 347530.068266 	improvement:  0.0
iteration 35 	loss: 347530.068266 	improvement:  0.0
iteration 36 	loss: 347530.068266 	improvement:  0.0
iteration 37 	loss: 347530.068266 	improvement:  0.0
iteration 38 	loss: 347530.068266 	improvement:  0.0
iteration 39 	loss: 347530.068266 	improvement:  0.0
iteration 40 	loss: 347530.068266 	improvement:  0.0
iteration 41 	loss: 347530.068266 	improvement:  0.0
iteration 42 	loss: 347530.068266 	improvement:  0.0
iteration 43 	loss: 347530.068266 	improvement:  0.0
iteration 44 	loss: 347530.068266 	improvement:  0.0
iteration 45 	loss: 347530.068266 	improvement:  0.0
iteration 46 	loss: 347530.068266 	improvement:  0.0
iteration 47 	loss: 347530.068266 	improvement:  0.0
iteration 48 	loss: 347530.068266 	improvement:  0.0
iteration 49 	loss: 347530.068266 	improvement:  0.0
iteration 50 	loss: 347530.068266 	improvement:  0.0
iteration 51 	loss: 347530.068266 	improvement:  0.0
iteration 52 	loss: 347530.068266 	improvement:  0.0
iteration 53 	loss: 347530.068266 	improvement:  0.0
iteration 54 	loss: 347530.068266 	improvement:  0.0
iteration 55 	loss: 347530.068266 	improvement:  0.0
iteration 56 	loss: 347530.068266 	improvement:  0.0
iteration 57 	loss: 347530.068266 	improvement:  0.0
iteration 58 	loss: 347530.068266 	improvement:  0.0
iteration 59 	loss: 347530.068266 	improvement:  0.0
iteration 60 	loss: 347530.068266 	improvement:  0.0
iteration 61 	loss: 347530.068266 	improvement:  0.0
iteration 62 	loss: 347530.068266 	improvement:  0.0
iteration 63 	loss: 347530.068266 	improvement:  0.0
iteration 64 	loss: 347530.068266 	improvement:  0.0
iteration 65 	loss: 347530.068266 	improvement:  0.0
iteration 66 	loss: 347530.068266 	improvement:  0.0
iteration 67 	loss: 347530.068266 	improvement:  0.0
iteration 68 	loss: 347530.068266 	improvement:  0.0
iteration 69 	loss: 347530.068266 	improvement:  0.0
iteration 70 	loss: 347530.068266 	improvement:  0.0
iteration 71 	loss: 347530.068266 	improvement:  0.0
iteration 72 	loss: 347530.068266 	improvement:  0.0
iteration 73 	loss: 347530.068266 	improvement:  0.0
iteration 74 	loss: 347530.068266 	improvement:  0.0
iteration 75 	loss: 347530.068266 	improvement:  0.0
iteration 76 	loss: 347530.068266 	improvement:  0.0
iteration 77 	loss: 347530.068266 	improvement:  0.0
iteration 78 	loss: 347530.068266 	improvement:  0.0
iteration 79 	loss: 347530.068266 	improvement:  0.0
iteration 80 	loss: 347530.068266 	improvement:  0.0
iteration 81 	loss: 347530.068266 	improvement:  0.0
iteration 82 	loss: 347530.068266 	improvement:  0.0
iteration 83 	loss: 347530.068266 	improvement:  0.0
iteration 84 	loss: 347530.068266 	improvement:  0.0
iteration 85 	loss: 347530.068266 	improvement:  0.0
iteration 86 	loss: 347530.068266 	improvement:  0.0
iteration 87 	loss: 347530.068266 	improvement:  0.0
iteration 88 	loss: 347530.068266 	improvement:  0.0
iteration 89 	loss: 347530.068266 	improvement:  0.0
iteration 90 	loss: 347530.068266 	improvement:  0.0
iteration 91 	loss: 347530.068266 	improvement:  0.0
iteration 92 	loss: 347530.068266 	improvement:  0.0
iteration 93 	loss: 347530.068266 	improvement:  0.0
iteration 94 	loss: 347530.068266 	improvement:  0.0
iteration 95 	loss: 347530.068266 	improvement:  0.0
iteration 96 	loss: 347530.068266 	improvement:  0.0
iteration 97 	loss: 347530.068266 	improvement:  0.0
iteration 98 	loss: 347530.068266 	improvement:  0.0
iteration 99 	loss: 347530.068266 	improvement:  0.0
iteration 100 	loss: 347530.068266 	improvement:  0.0
--- Execution Time ---
--- 120.233675003 seconds ---
